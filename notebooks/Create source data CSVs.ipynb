{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ec28092-a4cc-4090-ae98-62b5a757e66c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pycountry\n",
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e50af95-fbe7-4a88-9fac-3ec3cadd81fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS workspace.default.source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f8a2c04-0334-4a45-9da7-e950164df3a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import pandas as pd\n",
    "\n",
    "# High-risk countries (cleaned and matched to pycountry naming)\n",
    "high_risk_countries = [\n",
    "    \"Algeria\", \"Angola\", \"Bolivia\", \"Bulgaria\", \"Burkina Faso\", \"Cameroon\", \"Côte d'Ivoire\",\n",
    "    \"Democratic People's Republic of Korea\", \"Democratic Republic of the Congo\", \"Haiti\",\n",
    "    \"Iran\", \"Kenya\", \"Lao People's Democratic Republic\", \"Lebanon\", \"Monaco\", \"Mozambique\",\n",
    "    \"Myanmar\", \"Namibia\", \"Nepal\", \"Nigeria\", \"Senegal\", \"South Africa\", \"South Sudan\",\n",
    "    \"Syrian Arab Republic\", \"Venezuela\", \"Viet Nam\", \"Virgin Islands, British\", \"Yemen\"\n",
    "]\n",
    "\n",
    "\n",
    "# Get all recognized countries using pycountry\n",
    "all_countries = {country.name for country in pycountry.countries}\n",
    "\n",
    "# Build AML risk score table\n",
    "aml_risk_data = []\n",
    "for country in sorted(all_countries):\n",
    "    risk = \"High\" if country in high_risk_countries else \"Low\"\n",
    "    aml_risk_data.append({\"country\": country, \"aml_risk_score\": risk})\n",
    "\n",
    "# Convert to DataFrame\n",
    "aml_risk_df = spark.createDataFrame(aml_risk_data)\n",
    "\n",
    "# Save as CSV\n",
    "aml_risk_df.write.mode(\"overwrite\").option(\"header\", \"true\").format(\"csv\").save(\"/Volumes/workspace/default/source/aml_risk\")\n",
    "\n",
    "print(\"✅ aml_risk_scores.csv file generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5723f7-998f-4fae-b0e7-13992d2a5cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aml_risk_df.toPandas().to_csv(\"/Workspace/Users/tjeerdteduits@gmail.com/KYC-assessment/data/aml_risk_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c837c0f2-d3c9-4fc6-a11d-c06079929867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_CLIENTS = 1000\n",
    "NUM_TRANSACTIONS = 15000\n",
    "\n",
    "# Possible client countries; countries in which van Lanschot Kempen operates\n",
    "client_countries = [\n",
    "    \"Netherlands\", \"Belgium\", \"Germany\", \"France\", \"Switzerland\", \"Italy\",\n",
    "    \"Spain\", \"Austria\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\"\n",
    "]\n",
    "\n",
    "# --- Create clients.csv ---\n",
    "def random_birthdate(min_age=18, max_age=85):\n",
    "    today = datetime.today()\n",
    "    age = random.randint(min_age, max_age)\n",
    "    birthdate = today - timedelta(days=age * 365 + random.randint(0, 364))\n",
    "    return birthdate.date().isoformat()\n",
    "\n",
    "client_data = [\n",
    "    (f\"C{str(i).zfill(4)}\", fake.name(), random_birthdate(), random.choice(client_countries))\n",
    "    for i in range(1, NUM_CLIENTS +1)\n",
    "]\n",
    "\n",
    "clients_schema = StructType([\n",
    "    StructField(\"client_id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"date_of_birth\", StringType(), False),\n",
    "    StructField(\"country\", StringType(), False)\n",
    "])\n",
    "\n",
    "clients_df = spark.createDataFrame(client_data, schema=clients_schema)\n",
    "\n",
    "# --- Save CSVs ---\n",
    "clients_df.write.mode(\"overwrite\").option(\"header\", \"true\").format(\"csv\").save(\"/Volumes/workspace/default/source/clients\")\n",
    "\n",
    "print(\"✅ clients.csv files generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6912e84-eb03-4507-bd2f-8f7eb03b6425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clients_df.toPandas().to_csv(\"/Workspace/Users/tjeerdteduits@gmail.com/KYC-assessment/data/clients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9799cb-6f3c-4199-85f4-99b8e0d0dfb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Create transactions.csv ---\n",
    "\n",
    "# Assign 5% high-risk counterparties\n",
    "num_high_risk = int(NUM_TRANSACTIONS * 0.05)\n",
    "num_low_risk = NUM_TRANSACTIONS - num_high_risk\n",
    "counterparty_countries = (\n",
    "    np.random.choice(client_countries, num_low_risk).tolist() +\n",
    "    np.random.choice(high_risk_countries, num_high_risk).tolist()\n",
    ")\n",
    "random.shuffle(counterparty_countries)\n",
    "\n",
    "client_ids = [row[0] for row in client_data]\n",
    "credit_debit = [\"debit\", \"credit\"]\n",
    "credit_debit_list = np.random.choice(credit_debit, NUM_TRANSACTIONS).tolist()\n",
    "transaction_type = [\"cash\", \"wire\", \"online payment\", \"internal transfer\"]\n",
    "types_list = np.random.choice(transaction_type, NUM_TRANSACTIONS).tolist()\n",
    "\n",
    "transaction_rows = []\n",
    "\n",
    "for i in range(NUM_TRANSACTIONS):\n",
    "    transaction_id = f\"T{str(i+1).zfill(5)}\"\n",
    "    client_id = random.choice(client_ids)\n",
    "    transaction_amount = np.round(random.expovariate(1/2000), 2)\n",
    "    transaction_date = (datetime(2024, 1, 1) + timedelta(days=random.randint(0, 365))).isoformat()\n",
    "    counterparty_id = f\"CP{random.randint(10000, 99999)}\"\n",
    "    counterparty_country = counterparty_countries[i]\n",
    "    credit_debit = credit_debit_list[i]\n",
    "    transaction_type = types_list[i]\n",
    "\n",
    "    transaction_rows.append((\n",
    "        transaction_id, client_id, transaction_amount, transaction_date,\n",
    "        counterparty_id, counterparty_country, credit_debit, transaction_type\n",
    "    ))\n",
    "\n",
    "# -----------------------------\n",
    "# Define schema and create Spark DataFrame\n",
    "# -----------------------------\n",
    "transactions_schema = StructType([\n",
    "    StructField(\"transaction_id\", StringType(), False),\n",
    "    StructField(\"client_id\", StringType(), False),\n",
    "    StructField(\"transaction_amount\", DoubleType(), False),\n",
    "    StructField(\"transaction_date\", StringType(), False),\n",
    "    StructField(\"counterparty_id\", StringType(), False),\n",
    "    StructField(\"counterparty_country\", StringType(), False),\n",
    "    StructField(\"credit_debit\", StringType(), False),\n",
    "    StructField(\"transaction_type\", StringType(), False)\n",
    "])\n",
    "\n",
    "transactions_df = spark.createDataFrame(transaction_rows, schema=transactions_schema)\n",
    "\n",
    "# --- Save CSVs ---\n",
    "transactions_df.write.mode(\"overwrite\").option(\"header\", \"true\").format(\"csv\").save(\"/Volumes/workspace/default/source/transactions\")\n",
    "\n",
    "print(\"✅ transactions.csv files generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f13c393c-16f0-4680-bb64-8f3e1c460b23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_df.toPandas().to_csv(\"/Workspace/Users/tjeerdteduits@gmail.com/KYC-assessment/data/transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4347ecfd-eb06-4248-9c7c-b8d6280d2caf",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"path\":946},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754331257843}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/default/source/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb45e509-055e-48a2-a404-576b337c25c9",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754333285839}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754333316217}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clients_read = spark.read.option(\"header\", \"true\").csv(\"/Volumes/workspace/default/source/clients/\")\n",
    "clients_read.display()\n",
    "\n",
    "transactions_read = spark.read.option(\"header\", \"true\").csv(\"/Volumes/workspace/default/source/transactions/\")\n",
    "transactions_read.display()\n",
    "\n",
    "aml_risk_df_read = spark.read.option(\"header\", \"true\").csv(\"/Volumes/workspace/default/source/aml_risk_df/\")\n",
    "aml_risk_df_read.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3815260669988897,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Create source data CSVs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
