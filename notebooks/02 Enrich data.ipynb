{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af5110ce-6de1-4999-adea-696776a2096f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create schema (bronze) if not exists\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "\n",
    "spark.sql(\"SELECT current_catalog(), current_database()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "759d166c-0119-4e53-86e4-dbd3a828441d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, sum as _sum, count as _count, unix_timestamp\n",
    "\n",
    "clients_df = spark.table(\"bronze.clients\")\n",
    "transactions_df = spark.table(\"bronze.transactions\")\n",
    "aml_risk_df = spark.table(\"bronze.aml_risk_score\")\n",
    "\n",
    "# Join AML risk scores to clients\n",
    "clients_enriched_df = clients_df.join(aml_risk_df, on=\"country\", how=\"left\")\n",
    "\n",
    "# Join AML scores to counterparty_country in transactions\n",
    "transactions_enriched_df = (\n",
    "    transactions_df\n",
    "    .join(aml_risk_df.withColumnRenamed(\"country\", \"counterparty_country\")\n",
    "                      .withColumnRenamed(\"aml_risk_score\", \"aml_risk_score_counterparty\"),\n",
    "          on=\"counterparty_country\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Join client AML score\n",
    "transactions_enriched_df = transactions_enriched_df.join(\n",
    "    clients_enriched_df.select(\"client_id\", \"aml_risk_score\"),\n",
    "    on=\"client_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Make sure transaction_date is timestamp\n",
    "transactions_enriched_df = transactions_enriched_df.withColumn(\"transaction_ts\", col(\"transaction_date\").cast(\"timestamp\"))\n",
    "\n",
    "# Define a 30-day rolling window per client #TODO: set as parameter\n",
    "rolling_window = (\n",
    "    Window.partitionBy(\"client_id\")\n",
    "          .orderBy(col(\"transaction_ts\").cast(\"long\"))\n",
    "          .rangeBetween(-30 * 86400, 0)  # 30 days in seconds\n",
    ")\n",
    "\n",
    "# Add rolling sum and count columns\n",
    "transactions_enriched_df = (\n",
    "    transactions_enriched_df\n",
    "    .withColumn(\"rolling_txn_count_30d\", _count(\"transaction_id\").over(rolling_window))\n",
    "    .withColumn(\"rolling_txn_sum_30d\", _sum(\"transaction_amount\").over(rolling_window))\n",
    ")\n",
    "\n",
    "# Write to silver\n",
    "clients_enriched_df.write.mode(\"overwrite\").saveAsTable(\"silver.clients_enriched\")\n",
    "transactions_enriched_df.write.mode(\"overwrite\").saveAsTable(\"silver.transactions_enriched\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02 Enrich data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
